<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  
  <!-- Favicon code from realfavicongenerator.net -->
<link rel="apple-touch-icon" type="image/png" sizes="16x16" href="/assets/img/icons/robot.png"> 
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/icons/robot.png"> 
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#8b51a3">
<meta name="msapplication-TileColor" content="#563d7c">
<meta name="theme-color" content="#ffffff">

  <!--jQuery-->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-iYQeCzEYFbKjA/T2uDLTpkwGzCiq6soy8tYaI1GyVh/UjpbCx/TYkiZhlZB6+fzT" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.6/dist/umd/popper.min.js" integrity="sha384-oBqDVmMz9ATKxIep9tiCxS/Z9fNfEXiDAYTujMAeBAsjFuCZSmKbSSUnQlmh/jp3" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.1/dist/js/bootstrap.min.js" integrity="sha384-7VPbUDkoPSGFnVtYi0QogXtr74QeVeeIs99Qfg5YCF+TidwNdjvaKZX19NZ/e6oz" crossorigin="anonymous"></script>

  <!-- Fonts & Icons -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css" integrity="sha256-4rTIfo5GQTi/7UJqoyUJQKzxW8VN/YBH31+Cy+vTZj4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Publications | Puze Liu - 刘普泽</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Publications" />
<meta name="author" content="Puze Liu" />
<meta property="og:locale" content="en_GB" />
<meta name="description" content="List of publications" />
<meta property="og:description" content="List of publications" />
<link rel="canonical" href="http://localhost:4000/publications.html" />
<meta property="og:url" content="http://localhost:4000/publications.html" />
<meta property="og:site_name" content="Puze Liu - 刘普泽" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Publications" />
<meta name="twitter:site" content="@liu_puze" />
<meta name="twitter:creator" content="@Puze Liu" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Puze Liu"},"description":"List of publications","headline":"Publications","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/head.png"},"name":"Puze Liu"},"url":"http://localhost:4000/publications.html"}</script>
<!-- End Jekyll SEO tag -->

</head>
<body>
  <div class="container">
    

<section id="header-nav">
  <header>
    <nav class="navbar navbar-expand-md bg-light" style="background-color: #ffffff;">
      <div class="container-fluid mt-3">
      <!-- <image class="icon" src="/assets/img/icons/robot.png"></image> -->
      <a class="navbar-brand my-auto me-5" href="/"><image class="icon" src="/assets/img/icons/robot-mono.png"></image></a>
      <button class="navbar-toggler my-auto" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>

      <div class="collapse navbar-collapse mb-0 pb-3" id="navbarSupportedContent">
        <ul class="navbar-nav">
          
          <li class="nav-item btn-nav my-auto mx-auto pe-3 text-center ">
            <a class="nav-link" href="/">
              <span data-hover="Home">Home</span>
            </a>
          </li>
          <li class="nav-item my-auto mx-auto pe-3 text-center current">
            <a class="nav-link active" aria-current="page" href="">Publications</a>
          </li>
          
          <li class="nav-item btn-nav my-auto mx-auto pe-3 text-center ">
            <a class="nav-link" href="/presentations.html">
              <span data-hover="Presentations">Presentations</span>
            </a>
          </li>
          
          
          <li class="nav-item btn-nav my-auto mx-auto pe-3 text-center ">
            <a class="nav-link" href="/blog">
              <span data-hover="Blog">Blog</span>
            </a>
          </li>
          
          
          
          <!-- presentations -->
          
        </ul>
      </div>
    </div>
    </nav>
  </header>
</section>
</div>
<!--publications.js-->
<script type="text/javascript" src="/assets/js/publications.js"></script>
<div id="publications">
  <section class="bg"></section>
  <h1 class="title">Publications</h1>
  <h2 class="bibliography">Journal Articles</h2>
<h3 class="bibliography">2025</h3>
<ol class="bibliography"><li>----
----
<!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="TRO_ATACOM"><div class="pub-illustration">
      <img src="/assets/img/air_hockey_atacom.gif" alt="Safe Reinforcement Learning on the Constraint Manifold: Theory and Applications illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Safe Reinforcement Learning on the Constraint Manifold: Theory and Applications
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">
            <em>Puze Liu</em>,&nbsp;Bou-Ammar Haitham,&nbsp;Jan Peters,&nbsp;and Tateo Davide
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    IEEE Transactions on Robotics (T-RO), vol. , pp. 3442-3461, 2025
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>]
      [<a href="http://arxiv.org/abs/2404.09080" class="btn btn-sm z-depth-0" role="button">arXiv</a>]
      [<a href="https://www.ias.informatik.tu-darmstadt.de/uploads/Team/PuzeLiu/TRO_ATACOM_submitted.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="https://puzeliu.github.io/TRO-ATACOM" class="btn btn-sm z-depth-0" role="button">URL</a>]
      [<a href="http://doi.org/10.1109/TRO.2025.3567477" class="btn btn-sm z-depth-0" role="button">DOI</a>]
    </div>

  <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Integrating learning-based techniques, especially reinforcement learning, into robotics is promising for solving complex problems in unstructured environments. However, most existing approaches are trained in well-tuned simulators and subsequently deployed on real robots without online fine-tuning. In this setting, the simulation’s realism seriously impacts the deployment’s success rate. Instead, learning with real-world interaction data offers a promising alternative: not only eliminates the need for a fine-tuned simulator but also applies to a broader range of tasks where accurate modeling is unfeasible. One major problem for on-robot reinforcement learning is ensuring safety, as uncontrolled exploration can cause catastrophic damage to the robot or the environment. Indeed, safety specifications, often represented as constraints, can be complex and non-linear, making safety challenging to guarantee in learning systems. In this paper, we show how we can impose complex safety constraints on learning-based robotics systems in a principled manner, both from theoretical and practical points of view. Our approach is based on the concept of the Constraint Manifold, representing the set of safe robot configurations. Exploiting differential geometry techniques, i.e., the tangent space, we can construct a safe action space, allowing learning agents to sample arbitrary actions while ensuring safety. We demonstrate the method’s effectiveness in a real-world Robot Air Hockey task, showing that our method can handle high-dimensional tasks with complex constraints. Videos of the real robot experiments are available on the project website.</p>
    </div>
  </div>
</div></li>
<li>----
----
<!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="RAL_2025_Friction_Estimation"><div class="pub-illustration">
      <img src="/assets/img/adaptive_friction.jpg" alt="Adaptive control based friction estimation for tracking control of robot manipulators illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Adaptive control based friction estimation for tracking control of robot manipulators
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">Junning Huang,&nbsp;Davide Tateo,&nbsp;
            <em>Puze Liu</em>,&nbsp;and Jan Peters
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    IEEE Robotics and Automation Letters, vol. 10, pp. 2454-2461, 2025
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a href="https://arxiv.org/pdf/2409.05054" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="http://doi.org/10.1109/LRA.2025.3530159" class="btn btn-sm z-depth-0" role="button">DOI</a>]
    </div>

  
  </div>
</div></li>
<li>----
----
<!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="TASE_2025_ROSCOM"><div class="pub-content">
    
  <!-- Title -->
  <div class="title">ROSCOM: Robust Safe Reinforcement Learning on Stochastic Constraint Manifolds
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">Shangding Gu,&nbsp;
            <em>Puze Liu</em>,&nbsp;Alap Kshirsagar,&nbsp;Guang Chen,&nbsp;Jan Peters,&nbsp;and Alois Knoll
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    IEEE Transactions on Automation Science and Engineering, vol. 22, pp. 5841-5851, 2025
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a href="https://www.ias.informatik.tu-darmstadt.de/uploads/Team/AlapKshirsagar/2024-roscom-tase.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="http://doi.org/10.1109/TASE.2024.3431530" class="btn btn-sm z-depth-0" role="button">DOI</a>]
    </div>

  
  </div>
</div></li></ol>
<h3 class="bibliography">2024</h3>
<ol class="bibliography"><li>----
----
<!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="TRO_2024_Fast_Kinodynamic_Planning"><div class="pub-illustration">
      <img src="/assets/img/air_hockey_dynamic.gif" alt="Fast Kinodynamic Planning on the Constraint Manifold With Deep Neural Networks illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Fast Kinodynamic Planning on the Constraint Manifold With Deep Neural Networks
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">Piotr Kicki,&nbsp;
            <em>Puze Liu</em>,&nbsp;Davide Tateo,&nbsp;Haitham Bou-Ammar,&nbsp;Krzysztof Walas,&nbsp;Piotr Skrzypczyński,&nbsp;and Jan Peters
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    IEEE Transactions on Robotics (T-RO), vol. 40, pp. 277-297, 2024
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>]
      [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10292912" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="http://doi.org/10.1109/TRO.2023.3326922" class="btn btn-sm z-depth-0" role="button">DOI</a>]
    </div>

  <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Motion planning is a mature area of research in robotics with many well-established methods based on optimization or sampling the state space, suitable for solving kinematic motion planning. However, when dynamic motions under constraints are needed and computation time is limited, fast kinodynamic planning on the constraint manifold is indispensable. In recent years, learning-based solutions have become alternatives to classical approaches, but they still lack comprehensive handling of complex constraints, such as planning on a lower dimensional manifold of the task space while considering the robot’s dynamics. This article introduces a novel learning-to-plan framework that exploits the concept of constraint manifold, including dynamics, and neural planning methods. Our approach generates plans satisfying an arbitrary set of constraints and computes them in a short constant time, namely the inference time of a neural network. This allows the robot to plan and replan reactively, making our approach suitable for dynamic environments. We validate our approach on two simulated tasks and in a demanding real-world scenario, where we use a Kuka LBR Iiwa 14 robotic arm to perform the hitting movement in robotic air hockey.</p>
    </div>
  </div>
</div></li></ol>
<h3 class="bibliography">2023</h3>
<ol class="bibliography"><li>----
----
<!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="IJRR_2023_CEP"><div class="pub-illustration">
      <img src="/assets/img/cep_ijrr.jpg" alt="Composable energy policies for reactive motion generation and reinforcement learning illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Composable energy policies for reactive motion generation and reinforcement learning
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">Julen Urain,&nbsp;Anqi Li,&nbsp;
            <em>Puze Liu</em>,&nbsp;Carlo D’Eramo,&nbsp;and Jan Peters
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    The International Journal of Robotics Research, vol. 42, pp. 827-858, 2023
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>]
      [<a href="https://www.ias.informatik.tu-darmstadt.de/uploads/Team/JulenUrainDeJesus/cep_ijrr_2023.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="https://doi.org/10.1177/02783649231179499" class="btn btn-sm z-depth-0" role="button">URL</a>]
      [<a href="http://doi.org/10.1177/02783649231179499" class="btn btn-sm z-depth-0" role="button">DOI</a>]
    </div>

  <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p> In this work, we introduce composable energy policies (CEP), a novel framework for multi-objective motion generation. We frame the problem of composing multiple policy components from a probabilistic view. We consider a set of stochastic policies represented in arbitrary task spaces, where each policy represents a distribution of the actions to solve a particular task. Then, we aim to find the action in the configuration space that optimally satisfies all the policy components. The presented framework allows the fusion of motion generators from different sources: optimal control, data-driven policies, motion planning, and handcrafted policies. Classically, the problem of multi-objective motion generation is solved by the composition of a set of deterministic policies, rather than stochastic policies. However, there are common situations where different policy components have conflicting behaviors, leading to oscillations or the robot getting stuck in an undesirable state. While our approach is not directly able to solve the conflicting policies problem, we claim that modeling each policy as a stochastic policy allows more expressive representations for each component in contrast with the classical reactive motion generation approaches. In some tasks, such as reaching a target in a cluttered environment, we show experimentally that CEP additional expressivity allows us to model policies that reduce these conflicting behaviors. A field that benefits from these reactive motion generators is the one of robot reinforcement learning. Integrating these policy architectures with reinforcement learning allows us to include a set of inductive biases in the learning problem. These inductive biases guide the reinforcement learning agent towards informative regions or improve collision safety while exploring. In our work, we show how to integrate our proposed reactive motion generator as a structured policy for reinforcement learning. Combining the reinforcement learning agent exploration with the prior-based CEP, we can improve the learning performance and explore safer. </p>
    </div>
  </div>
</div></li></ol>
<h2 class="bibliography">Conference Papers</h2>
<h3 class="bibliography">2025</h3>
<ol class="bibliography"><li>----
----
<!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="GRC_25_SafeFoundationModels"><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Towards Safe Robot Foundation Models Using Inductive Biases
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">Maximilian Tölle,&nbsp;Theo Gruner,&nbsp;Daniel Palenicek,&nbsp;Tim Schneider,&nbsp;Jonas Günster,&nbsp;Joe Watson,&nbsp;Davide Tateo,&nbsp;
            <em>Puze Liu</em>,&nbsp;and Jan Peters
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In German Robotics Conference (GRC), 2025
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a href="https://arxiv.org/pdf/2505.10219" class="btn btn-sm z-depth-0" role="button">PDF</a>]
    </div>

  
  </div>
</div></li>
<li>----
----
<!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="CoRL_2025_SYMDEX"><div class="pub-illustration">
      <img src="/assets/img/symdex.gif" alt="Morphologically Symmetric Reinforcement Learning for Ambidextrous Bimanual Manipulation illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Morphologically Symmetric Reinforcement Learning for Ambidextrous Bimanual Manipulation
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">Zechu Li,&nbsp;Yufeng Jin,&nbsp;Daniel Ordonez Apraez,&nbsp;Claudio Semini,&nbsp;
            <em>Puze Liu*</em>,&nbsp;and Georgia Chalvatzaki
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In Conference on Robot Learning (CoRL), 2025
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a href="https://arxiv.org/pdf/2505.05287" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="https://supersglzc.github.io/projects/symdex" class="btn btn-sm z-depth-0" role="button">URL</a>]
    </div>

  
  </div>
</div></li>
<li>----
----
<!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="IMCL_2025_MTCRL"><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Maximum Total Correlation Reinforcement Learning
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">Bang You,&nbsp;
            <em>Puze Liu</em>,&nbsp;Huaping Liu,&nbsp;Jan Peters,&nbsp;and Oleg Arenz
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In Forty-second International Conference on Machine Learning, 2025
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a href="https://openreview.net/pdf?id=8mScy0IDRl" class="btn btn-sm z-depth-0" role="button">PDF</a>]
    </div>

  
  </div>
</div></li>
<li>----
----
<!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="RSS_2025_AirHockey"><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Distilling Contact Planning for Fast Trajectory Optimization in Robot Air Hockey
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">Julius Jankowski,&nbsp;Ante Marić,&nbsp;
            <em>Puze Liu</em>,&nbsp;Davide Tateo,&nbsp;Jan Peters,&nbsp;and Sylvain Calinon
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In Proceedings of Robotics: Science and Systems, Jun, 2025
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a href="https://www.roboticsproceedings.org/rss21/p115.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="http://doi.org/10.15607/RSS.2025.XXI.115" class="btn btn-sm z-depth-0" role="button">DOI</a>]
    </div>

  
  </div>
</div></li></ol>
<h3 class="bibliography">2024</h3>
<ol class="bibliography"><li>----
----
<!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="NeurIPS_2024_Challenge"><div class="pub-illustration">
      <img src="/assets/img/air_hockey_challenge.jpg" alt="A Retrospective on the Robot Air Hockey Challenge: Benchmarking Robust, Reliable, and Safe Learning Techniques for Real-World Robotics illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">A Retrospective on the Robot Air Hockey Challenge: Benchmarking Robust, Reliable, and Safe Learning Techniques for Real-World Robotics
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">
            <em>Puze Liu</em>,&nbsp;Jonas Günster,&nbsp;Niklas Funk,&nbsp;Simon Gröger,&nbsp;Dong Chen,&nbsp;Haitham Bou-Ammar,&nbsp;Julius Jankowski,&nbsp;Ante Marić,&nbsp;Sylvain Calinon,&nbsp;Andrej Orsula,&nbsp;Miguel Olivares-Mendez,&nbsp;Hongyi Zhou,&nbsp;Rudolf Lioutikov,&nbsp;Gerhard Neumann,&nbsp;Amarildo Likmeta,&nbsp;Amirhossein Zhalehmehrabi,&nbsp;Thomas Bonenfant,&nbsp;Marcello Restelli,&nbsp;Davide Tateo,&nbsp;Ziyuan Liu,&nbsp;and Jan Peters
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In Proceedings of the 38th International Conference on Neural Information Processing Systems, 2024
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>]
      [<a href="https://openreview.net/pdf?id=gPLE4siNjO" class="btn btn-sm z-depth-0" role="button">PDF</a>]
    </div>

  <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Machine learning methods have a groundbreaking impact in many application domains, but their application on real robotic platforms is still limited. Despite the many challenges associated with combining machine learning technology with robotics, robot learning remains one of the most promising directions for enhancing the capabilities of robots. When deploying learning-based approaches on real robots, extra effort is required to address the challenges posed by various real-world factors. To investigate the key factors influencing real-world deployment and to encourage original solutions from different researchers, we organized the Robot Air Hockey Challenge at the NeurIPS 2023 conference. We selected the air hockey task as a benchmark, encompassing low-level robotics problems and high-level tactics. Different from other machine learning-centric benchmarks, participants need to tackle practical challenges in robotics, such as the sim-to-real gap, low-level control issues, safety problems, real-time requirements, and the limited availability of real-world data. Furthermore, we focus on a dynamic environment, removing the typical assumption of quasi-static motions of other real-world benchmarks. The competition’s results show that solutions combining learning-based approaches with prior knowledge outperform those relying solely on data when real-world deployment is challenging. Our ablation study reveals which real-world factors may be overlooked when building a learning-based solution. The successful real-world air hockey deployment of best-performing agents sets the foundation for future competitions and follow-up research directions.</p>
    </div>
  </div>
</div></li>
<li>----
----
<!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="CoRL_2024_DATACOM"><div class="pub-illustration">
      <img src="/assets/img/datacom.gif" alt="Handling Long-Term Safety and Uncertainty in Safe Reinforcement Learning illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Handling Long-Term Safety and Uncertainty in Safe Reinforcement Learning
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">Jonas Günster,&nbsp;
            <em>Puze Liu*</em>,&nbsp;Jan Peters,&nbsp;and Davide Tateo
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In 8th Annual Conference on Robot Learning, 2024
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a href="https://openreview.net/pdf?id=97QXO0uBEO" class="btn btn-sm z-depth-0" role="button">PDF</a>]
    </div>

  
  </div>
</div></li></ol>
<h3 class="bibliography">2023</h3>
<ol class="bibliography"><li>----
----
<!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="ICRA_2022_ReDSDF_ATACOM"><div class="pub-illustration">
      <img src="/assets/img/hri_real.gif" alt="Safe Reinforcement Learning of Dynamic High-Dimensional Robotic Tasks: Navigation, Manipulation, Interaction illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Safe Reinforcement Learning of Dynamic High-Dimensional Robotic Tasks: Navigation, Manipulation, Interaction
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">
            <em>Puze Liu</em>,&nbsp;Kuo Zhang,&nbsp;Davide Tateo,&nbsp;Snehal Jauhri,&nbsp;Zhiyuan Hu,&nbsp;Jan Peters,&nbsp;and Georgia Chalvatzaki
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), 2023
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>]
      [<a href="http://arxiv.org/abs/2209.13308" class="btn btn-sm z-depth-0" role="button">arXiv</a>]
      [<a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>]
      [<a href="https://arxiv.org/pdf/2209.13308.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>]
    </div>

  <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Safety is a crucial property of every robotic platform: any control policy should always comply with actuator limits and avoid 
                 collisions with the environment and humans. In reinforcement learning, safety is even more fundamental for exploring an 
                 environment without causing any damage. While there are many proposed solutions to the safe exploration problem, only a few of 
                 them can deal with the complexity of the real world. This paper introduces a new formulation of safe exploration for reinforcement 
                 learning of various robotic tasks. Our approach applies to a wide class of robotic platforms and enforces safety even under 
                 complex collision constraints learned from data by exploring the tangent space of the constraint manifold. Our proposed approach 
                 achieves state-of-the-art performance in simulated high-dimensional and dynamic tasks while avoiding collisions with the 
                 environment. We show safe real-world deployment of our learned controller on a TIAGo++ robot, achieving remarkable performance 
                 in manipulation and human-robot interaction tasks.</p>
    </div><!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ICRA_2022_ReDSDF_ATACOM</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Safe Reinforcement Learning of Dynamic High-Dimensional Robotic Tasks: Navigation, Manipulation, Interaction}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Puze and Zhang, Kuo and Tateo, Davide and Jauhri, Snehal and Hu, Zhiyuan and Peters, Jan and Chalvatzaki, Georgia}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">image</span> <span class="p">=</span> <span class="s">{/assets/img/hri_real.gif}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
  </div>
</div></li></ol>
<h3 class="bibliography">2022</h3>
<ol class="bibliography"><li>----
----
<!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="IROS_2022_ReDSDF"><div class="pub-illustration">
      <img src="/assets/img/tiago_sdf.gif" alt="Regularized Deep Signed Distance Fields for Reactive Motion Generation illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Regularized Deep Signed Distance Fields for Reactive Motion Generation
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">
            <em>Puze Liu</em>,&nbsp;Kuo Zhang,&nbsp;Davide Tateo,&nbsp;Snehal Jauhri,&nbsp;Jan Peters,&nbsp;and Chalvatzaki Georgia
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2022
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>]
      [<a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>]
      [<a href="https://www.ias.informatik.tu-darmstadt.de/uploads/Team/PuzeLiu/IROS_2022_ReDSDF.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="https://git.ias.informatik.tu-darmstadt.de/ias_code/iros2022/redsdf" class="btn btn-sm z-depth-0" role="button">Code</a>]
    </div>

  <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Autonomous robots should operate in real-world dynamic environments and collaborate with humans in tight spaces. A key component for allowing robots to leave structured lab and manufacturing settings is their ability to evaluate online and real-time collisions with the world around them. Distance-based constraints are fundamental for enabling robots to plan their actions and act safely, protecting both humans and their hardware. However, different applications require different distance resolutions, leading to various heuristic approaches for measuring distance fields w.r.t. obstacles, which are computationally expensive and hinder their application in dynamic obstacle avoidance use-cases. We propose Regularized Deep Signed Distance Fields (ReDSDF), a single neural implicit function that can compute smooth distance fields at any scale, with fine-grained resolution over high-dimensional manifolds and articulated bodies like humans, thanks to our effective data generation and a simple inductive bias during training. We demonstrate the effectiveness of our approach in representative simulated tasks for whole-body control (WBC) and safe Human-Robot Interaction (HRI) in shared workspaces. Finally, we provide proof of concept of a real-world application in a HRI handover task with a mobile manipulator robot.</p>
    </div><!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">IROS_2022_ReDSDF</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Regularized Deep Signed Distance Fields for Reactive Motion Generation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Puze and Zhang, Kuo and Tateo, Davide and Jauhri, Snehal and Peters, Jan and Georgia, Chalvatzaki}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">image</span> <span class="p">=</span> <span class="s">{/assets/img/tiago_sdf.gif}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
  </div>
</div></li>
<li>----
----
<!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="AISTATS_22_DR-CREPS"><div class="pub-illustration">
      <img src="/assets/img/drcreps.jpg" alt=" Dimensionality Reduction and Prioritized Exploration for Policy Search  illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title"> Dimensionality Reduction and Prioritized Exploration for Policy Search 
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">Marius Memmel,&nbsp;
            <em>Puze Liu*</em>,&nbsp;Davide Tateo,&nbsp;and Jan Peters
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In Proceedings of The 25th International Conference on Artificial Intelligence and Statistics (AISTATS), vol. 151, pp. 2134–2157, 2022
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>]
      [<a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>]
      [<a href="https://proceedings.mlr.press/v151/memmel22a/memmel22a.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="https://proceedings.mlr.press/v151/memmel22a.html" class="btn btn-sm z-depth-0" role="button">Supp</a>]
      [<a href="https://git.ias.informatik.tu-darmstadt.de/ias_code/aistats2022/dr-creps" class="btn btn-sm z-depth-0" role="button">Code</a>]
    </div>

  <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p> Black-box policy optimization is a class of reinforcement learning algorithms that explores and updates the policies at the parameter level. This class of algorithms is widely applied in robotics with movement primitives or non-differentiable policies. Furthermore, these approaches are particularly relevant where exploration at the action level could cause actuator damage or other safety issues. However, Black-box optimization does not scale well with the increasing dimensionality of the policy, leading to high demand for samples, which are expensive to obtain in real-world systems. In many practical applications, policy parameters do not contribute equally to the return. Identifying the most relevant parameters allows to narrow down the exploration and speed up the learning. Furthermore, updating only the effective parameters requires fewer samples, improving the scalability of the method. We present a novel method to prioritize the exploration of effective parameters and cope with full covariance matrix updates. Our algorithm learns faster than recent approaches and requires fewer samples to achieve state-of-the-art results. To select the effective parameters, we consider both the Pearson correlation coefficient and the Mutual Information. We showcase the capabilities of our approach on the Relative Entropy Policy Search algorithm in several simulated environments, including robotics simulations. Code is available at https://git.ias.informatik.tu-darmstadt.de/ias_code/aistats2022/dr-creps. </p>
    </div><!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">AISTATS_22_DR-CREPS</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ Dimensionality Reduction and Prioritized Exploration for Policy Search }</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Memmel, Marius and Liu, Puze and Tateo, Davide and Peters, Jan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of The 25th International Conference on Artificial Intelligence and Statistics (AISTATS)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2134--2157}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Camps-Valls, Gustau and Ruiz, Francisco J. R. and Valera, Isabel}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{151}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{correspondence}</span><span class="p">,</span>
  <span class="na">image</span> <span class="p">=</span> <span class="s">{/assets/img/drcreps.jpg}</span>
<span class="p">}</span></code></pre></figure>
    </div>
  </div>
</div></li>
<li>----
----
<!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="CORL_2021_ATACOM"><div class="pub-illustration">
      <img src="/assets/img/manifold.gif" alt="Robot Reinforcement Learning on the Constraint Manifold illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Robot Reinforcement Learning on the Constraint Manifold
    <!-- Additional Comments --><div class="comments">
    Best Paper Award Finalist
  </div></div>  
  <!-- Author -->
  <div class="author">
            <em>Puze Liu</em>,&nbsp;Davide Tateo,&nbsp;Haitham Bou-Ammar,&nbsp;and Jan Peters
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In Proceedings of the 5th Conference on Robot Learning (CoRL), vol. 164, pp. 1357–1366, 2022
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>]
      [<a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>]
      [<a href="https://proceedings.mlr.press/v164/liu22c/liu22c.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="https://proceedings.mlr.press/v164/liu22c.html" class="btn btn-sm z-depth-0" role="button">Supp</a>]
      [<a href="https://github.com/PuzeLiu/rl_on_manifold" class="btn btn-sm z-depth-0" role="button">Code</a>]
      [<a href="https://www.youtube.com/watch?v=1Ve4wig7Oi4" class="btn btn-sm z-depth-0" role="button">Website</a>]
    </div>

  <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Reinforcement learning in robotics is extremely challenging due to many practical issues, including safety, mechanical constraints, and wear and tear. Typically, these issues are not considered in the machine learning literature. One crucial problem in applying reinforcement learning in the real world is Safe Exploration, which requires physical and safety constraints satisfaction throughout the learning process.  To explore in such a safety-critical environment, leveraging known information such as robot models and constraints is beneficial to provide more robust safety guarantees. Exploiting this knowledge, we propose a novel method to learn robotics tasks in simulation efficiently while satisfying the constraints during the learning process.</p>
    </div><!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CORL_2021_ATACOM</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Robot Reinforcement Learning on the Constraint Manifold}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Puze and Tateo, Davide and Bou-Ammar, Haitham and Peters, Jan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 5th Conference on Robot Learning (CoRL)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1357--1366}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Faust, Aleksandra and Hsu, David and Neumann, Gerhard}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{164}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
  <span class="na">comments</span> <span class="p">=</span> <span class="s">{Best Paper Award Finalist}</span><span class="p">,</span>
  <span class="na">image</span> <span class="p">=</span> <span class="s">{/assets/img/manifold.gif}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
  </div>
</div></li></ol>
<h3 class="bibliography">2021</h3>
<ol class="bibliography"><li>----
----
<!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="IROS_2021_Air_Hockey"><div class="pub-illustration">
      <img src="/assets/img/air_hockey_iros.jpg" alt="Efficient and Reactive Planning for High Speed Robot Air Hockey illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Efficient and Reactive Planning for High Speed Robot Air Hockey
    <!-- Additional Comments --><div class="comments">
    Best Entertainment and Amusement Paper Award Finalist
  </div></div>  
  <!-- Author -->
  <div class="author">
            <em>Puze Liu</em>,&nbsp;Davide Tateo,&nbsp;Haitham Bou-Ammar,&nbsp;and Jan Peters
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 586-593, 2021
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>]
      [<a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>]
      [<a href="https://ieeexplore.ieee.org/document/9636263" class="btn btn-sm z-depth-0" role="button">HTML</a>]
      [<a href="https://www.ias.informatik.tu-darmstadt.de/uploads/Team/PuzeLiu/IROS_2021_Air_Hockey.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="http://doi.org/10.1109/IROS51168.2021.9636263" class="btn btn-sm z-depth-0" role="button">DOI</a>]
    </div>

  <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Highly dynamic robotic tasks require high-speed and reactive robots. These tasks are particularly challenging due to the physical constraints, hardware limitations, and the high uncertainty of dynamics and sensor measures. To face these issues, it’s crucial to design robotics agents that generate precise and fast trajectories and react immediately to environmental changes. Air hockey is an example of this kind of task. Due to the environment’s characteristics, it is possible to formalize the problem and derive clean mathematical solutions. For these reasons, this environment is perfect for pushing to the limit the performance of currently available general-purpose robotic manipulators. Using two Kuka Iiwa 14, we show how to design a policy for general-purpose robotic manipulators for the air hockey game. We demonstrate that a real robot arm can perform fast-hitting movements and that the two robots can play against each other on a medium-size air hockey table in simulation.</p>
    </div><!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">IROS_2021_Air_Hockey</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Efficient and Reactive Planning for High Speed Robot Air Hockey}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Puze and Tateo, Davide and Bou-Ammar, Haitham and Peters, Jan}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{586-593}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IROS51168.2021.9636263}</span><span class="p">,</span>
  <span class="na">comments</span> <span class="p">=</span> <span class="s">{Best Entertainment and Amusement Paper Award Finalist}</span><span class="p">,</span>
  <span class="na">image</span> <span class="p">=</span> <span class="s">{/assets/img/air_hockey_iros.jpg}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
  </div>
</div></li>
<li>----
----
<!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="RSS_21_CEP"><div class="pub-illustration">
      <img src="/assets/img/cep.jpg" alt="Composable Energy Policies for Reactive Motion Generation and Reinforcement Learning illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Composable Energy Policies for Reactive Motion Generation and Reinforcement Learning
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">Julen Urain,&nbsp;Anqi Li,&nbsp;
            <em>Puze Liu</em>,&nbsp;Carlo D’eramo,&nbsp;and Jan Peters
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In Robotics: Science and Systems XVII (R:SS 2021), Jul, 2021
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>]
      [<a href="https://www.ias.informatik.tu-darmstadt.de/uploads/Team/JulenUrainDeJesus/cep_rss_2021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="http://doi.org/10.15607/RSS.2021.XVII.052" class="btn btn-sm z-depth-0" role="button">DOI</a>]
    </div>

  <!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">RSS_21_CEP</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Composable Energy Policies for Reactive Motion Generation and Reinforcement Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Urain, Julen and Li, Anqi and Liu, Puze and D'eramo, Carlo and Peters, Jan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Robotics: Science and Systems XVII (R:SS 2021)}</span><span class="p">,</span>
  <span class="na">editors</span> <span class="p">=</span> <span class="s">{Dylan A. Shell and Marc Toussaint and M. Ani Hsieh}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.15607/RSS.2021.XVII.052}</span><span class="p">,</span>
  <span class="na">image</span> <span class="p">=</span> <span class="s">{/assets/img/cep.jpg}</span>
<span class="p">}</span></code></pre></figure>
    </div>
  </div>
</div></li></ol>
</div>

<!-- Footer -->
<footer>
  <div class="footer">
    Copyright © 2025
    <a href="">Puze Liu</a>.
    Powered by Jekyll.
  </div>
</footer>


<script type="text/javascript" src="/assets/js/jquery-3.3.1.min.js"></script>
<script type="text/javascript" src="/assets/js/Headroom.js"></script>
<script type="text/javascript" src="/assets/js/jQuery.headroom.js"></script>
<script type="text/javascript" src="/assets/js/custom.js"></script>


<script>
    var divs = document.querySelectorAll("div.project-content");
    $('div.project-content').each(function (index) { 
        var filename = $(this).text();
        filename = filename.replace(/\s/g, '');
        filename = filename.replace("/_posts/", "");
        filename = filename.replace(".md", ".html");
        filename = filename.substring(0, 4) + "/" + filename.substring(5);
        filename = filename.substring(0, 7) + "/" + filename.substring(8);
        filename = filename.substring(0, 10) + "/" + filename.substring(11);

        console.log(filename);
        $.ajax({ url: filename, dataType: "html", success: function(data) { 
            const node = new DOMParser().parseFromString(data, "text/html");
            divs[index].innerHTML = node.getElementById("post").getElementsByClassName("post-content")[0].innerHTML;
            } 
        })
    });

</script>
  </div>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css" integrity="sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js" integrity="sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          // customised options
          // • auto-render specific keys, e.g.:
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          // • rendering keys, e.g.:
          throwOnError : false
        });
    });
</script>
  <script type="module">
    // Import the functions you need from the SDKs you need
    import { initializeApp } from "https://www.gstatic.com/firebasejs/9.10.0/firebase-app.js";
    import { getAnalytics } from "https://www.gstatic.com/firebasejs/9.10.0/firebase-analytics.js";
    // TODO: Add SDKs for Firebase products that you want to use
    // https://firebase.google.com/docs/web/setup#available-libraries

    // Your web app's Firebase configuration
    // For Firebase JS SDK v7.20.0 and later, measurementId is optional
    const firebaseConfig = {
        apiKey: "AIzaSyB7md8A_0alXIvUwSlpHGW8F-i59SboSqE",
        authDomain: "puze-liu.firebaseapp.com",
        projectId: "puze-liu",
        storageBucket: "puze-liu.appspot.com",
        messagingSenderId: "895154462267",
        appId: "1:895154462267:web:b6265ec90951a8bc62061e",
        measurementId: "G-97L9JYTYVW"
    };

    // Initialize Firebase
    const app = initializeApp(firebaseConfig);
    const analytics = getAnalytics(app);
</script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-RNQHE0TJJL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-RNQHE0TJJL');
</script>
</body>

</html>