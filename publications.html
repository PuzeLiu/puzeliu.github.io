<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  
  <!-- Favicon code from realfavicongenerator.net -->
<link rel="apple-touch-icon" type="image/png" sizes="16x16" href="/assets/img/icons/robot.png"> 
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/icons/robot.png"> 
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#8b51a3">
<meta name="msapplication-TileColor" content="#563d7c">
<meta name="theme-color" content="#ffffff">

  <!--jQuery-->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-iYQeCzEYFbKjA/T2uDLTpkwGzCiq6soy8tYaI1GyVh/UjpbCx/TYkiZhlZB6+fzT" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.6/dist/umd/popper.min.js" integrity="sha384-oBqDVmMz9ATKxIep9tiCxS/Z9fNfEXiDAYTujMAeBAsjFuCZSmKbSSUnQlmh/jp3" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.1/dist/js/bootstrap.min.js" integrity="sha384-7VPbUDkoPSGFnVtYi0QogXtr74QeVeeIs99Qfg5YCF+TidwNdjvaKZX19NZ/e6oz" crossorigin="anonymous"></script>

  <!-- Fonts & Icons -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css" integrity="sha256-AbA177XfpSnFEvgpYu1jMygiLabzPCJCRIBtR5jGc0k=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
  <link href='//spoqa.github.io/spoqa-han-sans/css/SpoqaHanSans-kr.css' rel='stylesheet' type='text/css'>

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Publications | Puze Liu - 刘普泽</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Publications" />
<meta name="author" content="Puze Liu" />
<meta property="og:locale" content="en_GB" />
<meta name="description" content="List of publications" />
<meta property="og:description" content="List of publications" />
<link rel="canonical" href="http://localhost:4000/publications.html" />
<meta property="og:url" content="http://localhost:4000/publications.html" />
<meta property="og:site_name" content="Puze Liu - 刘普泽" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Publications" />
<meta name="twitter:site" content="@liu_puze" />
<meta name="twitter:creator" content="@Puze Liu" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Puze Liu"},"description":"List of publications","headline":"Publications","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/head.png"},"name":"Puze Liu"},"url":"http://localhost:4000/publications.html"}</script>
<!-- End Jekyll SEO tag -->

</head>
<body>
  <div class="container">
    

<section id="header-nav">
  <header>
    <nav class="navbar navbar-expand-md bg-light" style="background-color: #ffffff;">
      <div class="container-fluid mt-3">
      <!-- <image class="icon" src="/assets/img/icons/robot.png"></image> -->
      <a class="navbar-brand my-auto me-5" href="/"><image class="icon" src="/assets/img/icons/robot-mono.png"></image></a>
      <button class="navbar-toggler my-auto" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>

      <div class="collapse navbar-collapse mb-0 pb-3" id="navbarSupportedContent">
        <ul class="navbar-nav">
          
          <li class="nav-item btn-nav my-auto mx-auto pe-3 text-center ">
            <a class="nav-link" href="/">
              <span data-hover="Home">Home</span>
            </a>
          </li>
          <li class="nav-item my-auto mx-auto pe-3 text-center current"><a class="nav-link active" aria-current="page" href="">Publications</a></li>
          
          <li class="nav-item btn-nav my-auto mx-auto pe-3 text-center ">
            <a class="nav-link" href="/presentations.html">
              <span data-hover="Presentations">Presentations</span>
            </a>
          </li>
          
          
          <li class="nav-item btn-nav my-auto mx-auto pe-3 text-center ">
            <a class="nav-link" href="/blog">
              <span data-hover="Blog">Blog</span>
            </a>
          </li>
          
          
          
          <!-- presentations -->
          
        </ul>
      </div>
    </div>
    </nav>
  </header>
</section>
</div>
<!--publications.js-->
<script type="text/javascript" src="/assets/js/publications.js"></script>
<div id="publications">
  <section class="bg"></section>
  <h1 class="title">Publications</h1>
  <h2 class="bibliography">Pre-Prints</h2>
<h3 class="bibliography">2022</h3>
<ol class="bibliography"><li><!-- Entry bib key -->
<div id="ICRA_2022_Redsdf_Atacom">
  
  <!-- Title -->
  <div class="title">Safe Reinforcement Learning of Dynamic High-Dimensional Robotic Tasks: Navigation, Manipulation, Interaction
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">
            <em>Puze Liu</em>,&nbsp;Kuo Zhang,&nbsp;Davide Tateo,&nbsp;Snehal Jauhri,&nbsp;Zhiyuan Hu,&nbsp;Jan Peters,&nbsp;and Georgia Chalvatzaki
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    2022
  </div>

  <!-- Links/Buttons -->
  <div class="links">
      [<a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>]
      [<a href="http://arxiv.org/abs/2209.13308" class="btn btn-sm z-depth-0" role="button">arXiv</a>]
      [<a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>]
      [<a href="https://arxiv.org/pdf/2209.13308.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>]
  </div>

  <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Safety is a crucial property of every robotic platform: any control policy should always comply with actuator limits and avoid 
                 collisions with the environment and humans. In reinforcement learning, safety is even more fundamental for exploring an 
                 environment without causing any damage. While there are many proposed solutions to the safe exploration problem, only a few of 
                 them can deal with the complexity of the real world. This paper introduces a new formulation of safe exploration for reinforcement 
                 learning of various robotic tasks. Our approach applies to a wide class of robotic platforms and enforces safety even under 
                 complex collision constraints learned from data by exploring the tangent space of the constraint manifold. Our proposed approach 
                 achieves state-of-the-art performance in simulated high-dimensional and dynamic tasks while avoiding collisions with the 
                 environment. We show safe real-world deployment of our learned controller on a TIAGo++ robot, achieving remarkable performance 
                 in manipulation and human-robot interaction tasks.</p>
    </div><!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@preprint</span><span class="p">{</span><span class="nl">ICRA_2022_Redsdf_Atacom</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Safe Reinforcement Learning of Dynamic High-Dimensional Robotic Tasks: Navigation, Manipulation, Interaction}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Puze and Zhang, Kuo and Tateo, Davide and Jauhri, Snehal and Hu, Zhiyuan and Peters, Jan and Chalvatzaki, Georgia}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Robotics (cs.RO), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
</div></li></ol>
<h2 class="bibliography">Conference Papers</h2>
<h3 class="bibliography">2022</h3>
<ol class="bibliography"><li><!-- Entry bib key -->
<div id="IROS_2022_ReDSDF">
  
  <!-- Title -->
  <div class="title">Regularized Deep Signed Distance Fields for Reactive Motion Generation
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">
            <em>Puze Liu</em>,&nbsp;Kuo Zhang,&nbsp;Davide Tateo,&nbsp;Snehal Jauhri,&nbsp;Jan Peters,&nbsp;and Chalvatzaki Georgia
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, 2022
  </div>

  <!-- Links/Buttons -->
  <div class="links">
      [<a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>]
      [<a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>]
      [<a href="https://www.ias.informatik.tu-darmstadt.de/uploads/Team/PuzeLiu/IROS_2022_ReDSDF.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="https://git.ias.informatik.tu-darmstadt.de/ias_code/iros2022/redsdf" class="btn btn-sm z-depth-0" role="button">Code</a>]
  </div>

  <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Autonomous robots should operate in real-world dynamic environments and collaborate with humans in tight spaces. A key component for allowing robots to leave structured lab and manufacturing settings is their ability to evaluate online and real-time collisions with the world around them. Distance-based constraints are fundamental for enabling robots to plan their actions and act safely, protecting both humans and their hardware. However, different applications require different distance resolutions, leading to various heuristic approaches for measuring distance fields w.r.t. obstacles, which are computationally expensive and hinder their application in dynamic obstacle avoidance use-cases. We propose Regularized Deep Signed Distance Fields (ReDSDF), a single neural implicit function that can compute smooth distance fields at any scale, with fine-grained resolution over high-dimensional manifolds and articulated bodies like humans, thanks to our effective data generation and a simple inductive bias during training. We demonstrate the effectiveness of our approach in representative simulated tasks for whole-body control (WBC) and safe Human-Robot Interaction (HRI) in shared workspaces. Finally, we provide proof of concept of a real-world application in a HRI handover task with a mobile manipulator robot.</p>
    </div><!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">IROS_2022_ReDSDF</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Regularized Deep Signed Distance Fields for Reactive Motion Generation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Puze and Zhang, Kuo and Tateo, Davide and Jauhri, Snehal and Peters, Jan and Georgia, Chalvatzaki}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
</div></li>
<li><!-- Entry bib key -->
<div id="CORL_2021_Learning_on_the_Manifold">
  
  <!-- Title -->
  <div class="title">Robot Reinforcement Learning on the Constraint Manifold
    <!-- Additional Comments --><div class="comments">
    Best Paper Award Finalist
  </div></div>  
  <!-- Author -->
  <div class="author">
            <em>Puze Liu</em>,&nbsp;Davide Tateo,&nbsp;Haitham Bou-Ammar,&nbsp;and Jan Peters
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In Proceedings of the 5th Conference on Robot Learning, vol. 164, pp. 1357–1366, 2022
  </div>

  <!-- Links/Buttons -->
  <div class="links">
      [<a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>]
      [<a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>]
      [<a href="https://proceedings.mlr.press/v164/liu22c/liu22c.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="https://proceedings.mlr.press/v164/liu22c.html" class="btn btn-sm z-depth-0" role="button">Supp</a>]
      [<a href="https://github.com/PuzeLiu/rl_on_manifold" class="btn btn-sm z-depth-0" role="button">Code</a>]
      [<a href="https://www.youtube.com/watch?v=1Ve4wig7Oi4" class="btn btn-sm z-depth-0" role="button">Website</a>]
  </div>

  <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Reinforcement learning in robotics is extremely challenging due to many practical issues, including safety, mechanical constraints, and wear and tear. Typically, these issues are not considered in the machine learning literature. One crucial problem in applying reinforcement learning in the real world is Safe Exploration, which requires physical and safety constraints satisfaction throughout the learning process.  To explore in such a safety-critical environment, leveraging known information such as robot models and constraints is beneficial to provide more robust safety guarantees. Exploiting this knowledge, we propose a novel method to learn robotics tasks in simulation efficiently while satisfying the constraints during the learning process.</p>
    </div><!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CORL_2021_Learning_on_the_Manifold</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Robot Reinforcement Learning on the Constraint Manifold}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Puze and Tateo, Davide and Bou-Ammar, Haitham and Peters, Jan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 5th Conference on Robot Learning}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1357--1366}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Faust, Aleksandra and Hsu, David and Neumann, Gerhard}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{164}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
  <span class="na">comments</span> <span class="p">=</span> <span class="s">{Best Paper Award Finalist}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
</div></li>
<li><!-- Entry bib key -->
<div id="AISTATS_22_DR-CREPS">
  
  <!-- Title -->
  <div class="title"> Dimensionality Reduction and Prioritized Exploration for Policy Search 
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">Marius Memmel,&nbsp;
            <em>Puze Liu</em>,&nbsp;Davide Tateo,&nbsp;and Jan Peters
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In Proceedings of The 25th International Conference on Artificial Intelligence and Statistics, vol. 151, pp. 2134–2157, 2022
  </div>

  <!-- Links/Buttons -->
  <div class="links">
      [<a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>]
      [<a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>]
      [<a href="https://proceedings.mlr.press/v151/memmel22a/memmel22a.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="https://proceedings.mlr.press/v151/memmel22a.html" class="btn btn-sm z-depth-0" role="button">Supp</a>]
      [<a href="https://git.ias.informatik.tu-darmstadt.de/ias_code/aistats2022/dr-creps" class="btn btn-sm z-depth-0" role="button">Code</a>]
  </div>

  <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p> Black-box policy optimization is a class of reinforcement learning algorithms that explores and updates the policies at the parameter level. This class of algorithms is widely applied in robotics with movement primitives or non-differentiable policies. Furthermore, these approaches are particularly relevant where exploration at the action level could cause actuator damage or other safety issues. However, Black-box optimization does not scale well with the increasing dimensionality of the policy, leading to high demand for samples, which are expensive to obtain in real-world systems. In many practical applications, policy parameters do not contribute equally to the return. Identifying the most relevant parameters allows to narrow down the exploration and speed up the learning. Furthermore, updating only the effective parameters requires fewer samples, improving the scalability of the method. We present a novel method to prioritize the exploration of effective parameters and cope with full covariance matrix updates. Our algorithm learns faster than recent approaches and requires fewer samples to achieve state-of-the-art results. To select the effective parameters, we consider both the Pearson correlation coefficient and the Mutual Information. We showcase the capabilities of our approach on the Relative Entropy Policy Search algorithm in several simulated environments, including robotics simulations. Code is available at https://git.ias.informatik.tu-darmstadt.de/ias_code/aistats2022/dr-creps. </p>
    </div><!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">AISTATS_22_DR-CREPS</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ Dimensionality Reduction and Prioritized Exploration for Policy Search }</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Memmel, Marius and Liu, Puze and Tateo, Davide and Peters, Jan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of The 25th International Conference on Artificial Intelligence and Statistics}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2134--2157}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Camps-Valls, Gustau and Ruiz, Francisco J. R. and Valera, Isabel}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{151}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
</div></li></ol>
<h3 class="bibliography">2021</h3>
<ol class="bibliography"><li><!-- Entry bib key -->
<div id="IROS_2021_Air_Hockey">
  
  <!-- Title -->
  <div class="title">Efficient and Reactive Planning for High Speed Robot Air Hockey
    <!-- Additional Comments --><div class="comments">
    Best Entertainment and Amusement Paper Award Finalist
  </div></div>  
  <!-- Author -->
  <div class="author">
            <em>Puze Liu</em>,&nbsp;Davide Tateo,&nbsp;Haitham Bou-Ammar,&nbsp;and Jan Peters
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 586-593, 2021
  </div>

  <!-- Links/Buttons -->
  <div class="links">
      [<a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>]
      [<a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>]
      [<a href="https://ieeexplore.ieee.org/document/9636263" class="btn btn-sm z-depth-0" role="button">HTML</a>]
      [<a href="https://www.ias.informatik.tu-darmstadt.de/uploads/Team/PuzeLiu/IROS_2021_Air_Hockey.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="http://doi.org/10.1109/IROS51168.2021.9636263" class="btn btn-sm z-depth-0" role="button">DOI</a>]
  </div>

  <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Highly dynamic robotic tasks require high-speed and reactive robots. These tasks are particularly challenging due to the physical constraints, hardware limitations, and the high uncertainty of dynamics and sensor measures. To face these issues, it’s crucial to design robotics agents that generate precise and fast trajectories and react immediately to environmental changes. Air hockey is an example of this kind of task. Due to the environment’s characteristics, it is possible to formalize the problem and derive clean mathematical solutions. For these reasons, this environment is perfect for pushing to the limit the performance of currently available general-purpose robotic manipulators. Using two Kuka Iiwa 14, we show how to design a policy for general-purpose robotic manipulators for the air hockey game. We demonstrate that a real robot arm can perform fast-hitting movements and that the two robots can play against each other on a medium-size air hockey table in simulation.</p>
    </div><!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">IROS_2021_Air_Hockey</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Efficient and Reactive Planning for High Speed Robot Air Hockey}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Puze and Tateo, Davide and Bou-Ammar, Haitham and Peters, Jan}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{586-593}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IROS51168.2021.9636263}</span><span class="p">,</span>
  <span class="na">comments</span> <span class="p">=</span> <span class="s">{Best Entertainment and Amusement Paper Award Finalist}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
</div></li>
<li><!-- Entry bib key -->
<div id="RSS_21_CEP">
  
  <!-- Title -->
  <div class="title">Composable Energy Policies for Reactive Motion Generation and Reinforcement Learning
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">Julen Urain,&nbsp;Anqi Li,&nbsp;
            <em>Puze Liu</em>,&nbsp;Carlo D’eramo,&nbsp;and Jan Peters
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In Robotics: Science and Systems XVII (R:SS 2021), Jul, 2021
  </div>

  <!-- Links/Buttons -->
  <div class="links">
      [<a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>]
      [<a href="https://www.ias.informatik.tu-darmstadt.de/uploads/Team/JulenUrainDeJesus/cep_rss_2021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="http://doi.org/10.15607/RSS.2021.XVII.052" class="btn btn-sm z-depth-0" role="button">DOI</a>]
  </div>

  <!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">RSS_21_CEP</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Composable Energy Policies for Reactive Motion Generation and Reinforcement Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Urain, Julen and Li, Anqi and Liu, Puze and D'eramo, Carlo and Peters, Jan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Robotics: Science and Systems XVII (R:SS 2021)}</span><span class="p">,</span>
  <span class="na">editors</span> <span class="p">=</span> <span class="s">{Dylan A. Shell and Marc Toussaint and M. Ani Hsieh}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.15607/RSS.2021.XVII.052}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
</div></li></ol>
<h2 class="bibliography">Workshop Papers</h2>
<h3 class="bibliography">2022</h3>
<ol class="bibliography"><li><!-- Entry bib key -->
<div id="ICRA_Workshop_ReDSDF">
  
  <!-- Title -->
  <div class="title">ReDSDF: Regularized Deep Signed Distance Fields for Robotics
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">
            <em>Puze Liu</em>,&nbsp;Kuo Zhang,&nbsp;Davide Tateo,&nbsp;Snehal Jauhri,&nbsp;Jan Peters,&nbsp;and Georgia Chalvatzaki
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    ICRA Workshop: Motion Planning with Implicit Neural Representations of Geometry, 2022
  </div>

  <!-- Links/Buttons -->
  <div class="links">
      [<a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>]
  </div>

  <!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@techreport</span><span class="p">{</span><span class="nl">ICRA_Workshop_ReDSDF</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Puze and Zhang, Kuo and Tateo, Davide and Jauhri, Snehal and Peters, Jan and Chalvatzaki, Georgia}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ReDSDF: Regularized Deep Signed Distance Fields for Robotics}</span><span class="p">,</span>
  <span class="na">workshop</span> <span class="p">=</span> <span class="s">{ICRA Workshop: Motion Planning with Implicit Neural Representations of Geometry}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
</div></li></ol>
</div>

<!-- Footer -->
<footer>
  <div class="footer">
    Copyright © 2022
    <a href="">Puze Liu</a>.
    Powered by Jekyll.
  </div>
</footer>


<script type="text/javascript" src="/assets/js/jquery-3.3.1.min.js"></script>
<script type="text/javascript" src="/assets/js/Headroom.js"></script>
<script type="text/javascript" src="/assets/js/jQuery.headroom.js"></script>
<script type="text/javascript" src="/assets/js/custom.js"></script>


<script>
    var divs = document.querySelectorAll("div.project-content");
    $('div.project-content').each(function (index) { 
        var filename = $(this).text();
        filename = filename.replace(/\s/g, '');
        filename = filename.replace("/_posts/", "");
        filename = filename.replace(".md", ".html");
        filename = filename.substring(0, 4) + "/" + filename.substring(5);
        filename = filename.substring(0, 7) + "/" + filename.substring(8);
        filename = filename.substring(0, 10) + "/" + filename.substring(11);

        console.log(filename);
        $.ajax({ url: filename, dataType: "html", success: function(data) { 
            const node = new DOMParser().parseFromString(data, "text/html");
            divs[index].innerHTML = node.getElementById("post").getElementsByClassName("post-content")[0].innerHTML;
            } 
        })
    });

</script>
  </div>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css" integrity="sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js" integrity="sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          // customised options
          // • auto-render specific keys, e.g.:
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          // • rendering keys, e.g.:
          throwOnError : false
        });
    });
</script>
  <script type="module">
    // Import the functions you need from the SDKs you need
    import { initializeApp } from "https://www.gstatic.com/firebasejs/9.10.0/firebase-app.js";
    import { getAnalytics } from "https://www.gstatic.com/firebasejs/9.10.0/firebase-analytics.js";
    // TODO: Add SDKs for Firebase products that you want to use
    // https://firebase.google.com/docs/web/setup#available-libraries

    // Your web app's Firebase configuration
    // For Firebase JS SDK v7.20.0 and later, measurementId is optional
    const firebaseConfig = {
        apiKey: "AIzaSyB7md8A_0alXIvUwSlpHGW8F-i59SboSqE",
        authDomain: "puze-liu.firebaseapp.com",
        projectId: "puze-liu",
        storageBucket: "puze-liu.appspot.com",
        messagingSenderId: "895154462267",
        appId: "1:895154462267:web:b6265ec90951a8bc62061e",
        measurementId: "G-97L9JYTYVW"
    };

    // Initialize Firebase
    const app = initializeApp(firebaseConfig);
    const analytics = getAnalytics(app);
</script>
</body>

</html>