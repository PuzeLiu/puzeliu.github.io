<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  
  <!-- Favicon code from realfavicongenerator.net -->
<link rel="apple-touch-icon" type="image/png" sizes="16x16" href="/assets/img/icons/robot.png"> 
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/icons/robot.png"> 
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#8b51a3">
<meta name="msapplication-TileColor" content="#563d7c">
<meta name="theme-color" content="#ffffff">

  <!--jQuery-->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-iYQeCzEYFbKjA/T2uDLTpkwGzCiq6soy8tYaI1GyVh/UjpbCx/TYkiZhlZB6+fzT" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.6/dist/umd/popper.min.js" integrity="sha384-oBqDVmMz9ATKxIep9tiCxS/Z9fNfEXiDAYTujMAeBAsjFuCZSmKbSSUnQlmh/jp3" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.1/dist/js/bootstrap.min.js" integrity="sha384-7VPbUDkoPSGFnVtYi0QogXtr74QeVeeIs99Qfg5YCF+TidwNdjvaKZX19NZ/e6oz" crossorigin="anonymous"></script>

  <!-- Fonts & Icons -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css" integrity="sha256-4rTIfo5GQTi/7UJqoyUJQKzxW8VN/YBH31+Cy+vTZj4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Puze Liu (刘普泽) | Puze Liu - 刘普泽</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Puze Liu (刘普泽)" />
<meta name="author" content="Puze Liu" />
<meta property="og:locale" content="en_GB" />
<meta name="description" content="Puze Liu - Homepage" />
<meta property="og:description" content="Puze Liu - Homepage" />
<link rel="canonical" href="http://localhost:4000/" />
<meta property="og:url" content="http://localhost:4000/" />
<meta property="og:site_name" content="Puze Liu - 刘普泽" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Puze Liu (刘普泽)" />
<meta name="twitter:site" content="@liu_puze" />
<meta name="twitter:creator" content="@Puze Liu" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","author":{"@type":"Person","name":"Puze Liu"},"description":"Puze Liu - Homepage","headline":"Puze Liu (刘普泽)","name":"Puze Liu - 刘普泽","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/head.png"},"name":"Puze Liu"},"url":"http://localhost:4000/"}</script>
<!-- End Jekyll SEO tag -->

</head>
<body>
  <div class="container">
    

<section id="header-nav">
  <header>
    <nav class="navbar navbar-expand-md bg-light" style="background-color: #ffffff;">
      <div class="container-fluid mt-3">
      <!-- <image class="icon" src="/assets/img/icons/robot.png"></image> -->
      <a class="navbar-brand my-auto me-5" href="/"><image class="icon" src="/assets/img/icons/robot-mono.png"></image></a>
      <button class="navbar-toggler my-auto" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>

      <div class="collapse navbar-collapse mb-0 pb-3" id="navbarSupportedContent">
        <ul class="navbar-nav">
          
          <li class="nav-item my-auto mx-auto pe-3 text-center current">
            <a class="nav-link active" aria-current="page" href="/">Home</a>
          </li>
          
          <li class="nav-item btn-nav my-auto mx-auto pe-3 text-center ">
            <a class="nav-link" href="/publications.html">
              <span data-hover="Publications">Publications</span>
            </a>
          </li>
          
          
          <li class="nav-item btn-nav my-auto mx-auto pe-3 text-center ">
            <a class="nav-link" href="/presentations.html">
              <span data-hover="Presentations">Presentations</span>
            </a>
          </li>
          
          
          <li class="nav-item btn-nav my-auto mx-auto pe-3 text-center  ">
            <a class="nav-link" href="/blog">
              <span data-hover="Blog">Blog</span>
            </a>
          </li>
          
          
          <!-- publications -->
          
        </ul>
      </div>
    </div>
    </nav>
  </header>
</section>




</div><!-- This Tag means End .container -->
<div id="portfolio">
  <section id="about-me">
    <div class="row">
      <div class="img-wrap col-12 col-md-4">
        <div class="img">
          <img src="/assets/img/head.png" alt="user_image">
        </div>
        <ul id="icons">
          

<li>
  <a href="mailto:%70%75%7A%65.%6C%69%75@%72%6F%62%6F%74-%6C%65%61%72%6E%69%6E%67.%64%65" target="_blank" title="Email">
    <i class="fas fa-envelope"></i>
  </a>
</li>





<li>
  <a href="https://scholar.google.com/citations?user=zg-FMloAAAAJ" target="_blank" title="Google Scholar">
    <i class="ai ai-google-scholar"></i>
  </a>
</li>











<li>
  <a href="https://www.linkedin.com/in/puzeliu" target="_blank" title="Linkedin">
    <i class="fab fa-linkedin"></i>
  </a>
</li>



<li>
  <a href="https://github.com/PuzeLiu" target="_blank" title="Github">
    <i class="fab fa-github"></i>
  </a>
</li>









<li>
  <a href="https://twitter.com/liu_puze" target="_blank" title="Twitter">
    <i class="fa-brands fa-x-twitter"></i>
  </a>
</li>







        </ul>
      </div>
      <div class="text-wrap col-12 col-md-8">
        <h2 class="username">Puze Liu - 刘普泽</h2>
        <div class="description"><p>Senior Research Scientist &amp; Deputy Head <br /> <a href="https://www.dfki.de/sairol">System AI for Robot Learning (SAIROL)</a> in <a href="https://www.dfki.de">DFKI</a> <br /> <br /> I obtained my Ph.D. degree at <a href="https://www.ias.informatik.tu-darmstadt.de">Intelligent Autonomous Systems</a>, TU Darmstadt, supervised by <a href="https://www.ias.informatik.tu-darmstadt.de/Team/JanPeters">Prof. Jan Peters</a>. <br /> My research focus on empowering <strong>Robots</strong> with complex skills utilizing advanced <strong>Machine Learning</strong> techniques. Specifically, I’m focusing on the safety problems when deploying learned policy on a real robot.</p>
</div>
        <div class="research_interest"> 
  <p class="title">RESEARCH INTERESTS</p>
  <ul class="interests-list">
    
    <li class="interest">| Robotics</li>
    
    <li class="interest">| Robot Learning</li>
    
    <li class="interest">| Safe Reinforcement Learning</li>
    
    <li class="interest">| Control and Optimization</li>
    
    <li class="interest">| Robot Air Hockey</li>
    
    <li class="interest">| Human Robot Interaction</li>
    
    |
  </ul>
 </div>
      </div>
    </div>
    <div class="bg"></div>
  </section>
  <!-- career section -->
  <section id="career" class="row">
    <article class="exper col-12 col-md-12">
      
      
  <p class="title">NEWS</p>
  <ul class="news-list">
    
    <li class="new">
      <p class="date">2025-05-09 &nbsp; <a href="https://sites.google.com/view/leapride"><i class="fa-solid fa-link"></i></a></p>
      <p class="description">Our Workshop Proposal: "LeaPRiDE: Learning, Planning, and Reasoning in Dynamic Environments" has been accepted in IROS 2025!</p>
    </li>
    
    <li class="new">
      <p class="date">2025-05-01 &nbsp; <a href="https://arxiv.org/pdf/2407.03705"><i class="fa-solid fa-file-pdf"></i></a></p>
      <p class="description">Our Paper: "Maximum Total Correlation Reinforcement Learning" has been accepted in ICML 2025!</p>
    </li>
    
    <li class="new">
      <p class="date">2025-04-21</p>
      <p class="description">I have been selected as member of "<span class="em-color">R:SS Pioneers 2025</span>"!  <i class="fab fa-angellist"></i></p>
    </li>
    
    <li class="new">
      <p class="date">2025-04-11 &nbsp; <a href="https://arxiv.org/pdf/2407.03705"><i class="fa-solid fa-file-pdf"></i></a></p>
      <p class="description">Our Paper: "Distilling Contact Planning for Fast Trajectory Optimization in Robot Air Hockey" has been accepted in RSS 2025!</p>
    </li>
    
    <li class="new">
      <p class="date">2025-03-29 &nbsp; <a href="https://arxiv.org/pdf/2503.08479"><i class="fa-solid fa-file-pdf"></i></a></p>
      <p class="description">Our Paper: "Safe Reinforcement Learning on the Constraint Manifold: Theory and Applications" has been accepted in T-RO.</p>
    </li>
    
    <li class="new">
      <p class="date">2024-12-30 &nbsp; <a href="https://ieeexplore.ieee.org/abstract/document/10842510"><i class="fa-solid fa-file-pdf"></i></a></p>
      <p class="description">Our Paper: "Adaptive Control based Friction Estimation for Tracking Control of Robot Manipulators" has been accepted in RA-L!</p>
    </li>
    
    <li class="new">
      <p class="date">2024-10-08 &nbsp; <a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/12ba5de27afcff1a5c796de4a6392154-Abstract-Datasets_and_Benchmarks_Track.html"><i class="fa-solid fa-file-pdf"></i></a></p>
      <p class="description">1 paper accepted in the NeurIPS Datasets and Benchmarks Track: <br/> "A Retrospective on the Robot Air Hockey Challenge: Benchmarking Robust, Reliable, and Safe Learning Techniques for Real-world Robotics"</p>
    </li>
    
    <li class="new">
      <p class="date">2024-10-11 &nbsp; <a href="https://openreview.net/forum?id=97QXO0uBEO"><i class="fa-solid fa-file-pdf"></i></a></p>
      <p class="description">We got 2 papers accepted in CoRL: <br/> "Bridging the Gap Between Learning-to-Plan, Motion Primitives and Safe Reinforcement Learning" <a href="https://openreview.net/forum?id=ZdgaF8fOc0"><i class="fa-solid fa-file-pdf"></i></a> <br/> "Handling Long-Term Safety and Uncertainty in Safe Reinforcement Learning" </p>
    </li>
    
    <li class="new">
      <p class="date">2024-07-15 &nbsp; <a href="https://ieeexplore.ieee.org/abstract/document/10616119"><i class="fa-solid fa-file-pdf"></i></a></p>
      <p class="description">Our paper "ROSCOM: Robust Safe Reinforcement Learning on Stochastic Constraint Manifolds" has been accepted in the IEEE Transactions on Automation Science and Engineering (TASE).</p>
    </li>
    
    <li class="new">
      <p class="date">2023-12-15 &nbsp; <a href="https://neurips.cc/virtual/2023/competition/66598"><i class="fa-solid fa-link"></i></a></p>
      <p class="description">We have organized a workshop in the NeurIPS 2023 attached to "The Robot Air Hockey Challenge: Robust, Reliable, and Safe Learning Techniques for Real-world Robotics"!</p>
    </li>
    
    <li class="new">
      <p class="date">2023-10-15 &nbsp; <a href="https://arxiv.org/pdf/2301.04330.pdf"><i class="fa-solid fa-file-pdf"></i></a></p>
      <p class="description">Our paper "Fast Kinodynamic Planning on the Constraint Manifold with Deep Neural Networks" has been accepted for publication in the IEEE Transactions on Robotics (T-RO).</p>
    </li>
    
    <li class="new">
      <p class="date">2023-06-04 &nbsp; <a href="https://air-hockey-challenge.robot-learning.net"><i class="fa-solid fa-link"></i></a></p>
      <p class="description">Our competition "The Robot Air Hockey Challenge: Robust, Reliable, and Safe Learning Techniques for Real-world Robotics" has been accepted at the Neural Information Processing Systems (NeurIPS) 2023!</p>
    </li>
    
    <li class="new">
      <p class="date">2023-03-06 &nbsp; <a href="https://www.ias.informatik.tu-darmstadt.de/uploads/Site/EditPublication/urain_2023_cep_ijrr.pdf"><i class="fa-solid fa-file-pdf"></i></a></p>
      <p class="description">Our paper "Composable Energy Policies for Reactive Motion Generation and Reinforcement Learning" has been accepted for publication in the International Journal of Robotics Research (IJRR)!</p>
    </li>
    
    <li class="new">
      <p class="date">2023-01-17 &nbsp; <a href="https://arxiv.org/abs/2209.13308"><i class="fa-solid fa-file-pdf"></i></a></p>
      <p class="description">Our paper "Safe Reinforcement Learning of Dynamic High-Dimensional Robotic Tasks: Navigation, Manipulation, Interaction" has benn accepted at ICRA 2023! <i class="fab fa-angellist"></i></p>
    </li>
    
    <li class="new">
      <p class="date">2022-09-27</p>
      <p class="description">I won the "<span class="em-color">IROS Student Travel Award</span>"! <i class="fab fa-angellist"></i></p>
    </li>
    
    <li class="new">
      <p class="date">2022-07-01 &nbsp; <a href="https://ieeexplore.ieee.org/abstract/document/9981456"><i class="fa-solid fa-file-pdf"></i></a></p>
      <p class="description">Our paper "Regularized Deep Signed Distance Fields for Reactive Motion Generation" has benn accepted at IROS 2022!</p>
    </li>
    
    <li class="new">
      <p class="date">2022-01-18</p>
      <p class="description">Our paper "Dimensionality Reduction and Prioritized Exploration for Policy Search" is accepted at AISTATS 2022!</p>
    </li>
    
    <li class="new">
      <p class="date">2021-11-08 &nbsp; <a href="https://proceedings.mlr.press/v164/liu22c.html"><i class="fa-solid fa-file-pdf"></i></a></p>
      <p class="description">Our paper "Robot Reinforcement Learning on the Constraint Manifold" has been accepted at CoRL 2021 as oral presentation and selected as "<span class="em-color">Best Paper Award Finalist</span>"! <i class="fab fa-angellist"></i></p>
    </li>
    
    <li class="new">
      <p class="date">2021-09-30</p>
      <p class="description">Our paper "Efficient and Reactive Planning for High Speed Robot Air Hockey" has been accepted at IROS 2021 and selected as "<span class="em-color">Best Entertainment and Amusement Paper Award Finalist</span>"! <i class="fab fa-angellist"></i></p>
    </li>
    
  </ul>

    </article>
    <article class="skills col-12 col-md-6">
      
    </article>
  </section>

  <section id="recentpubs">
  <div class="recentpubs-wrap">
    <p class="title">SELECTED PUBLICATIONS</p>
    [<a class="btn" href="/publications" title="Publications">All Publications</a>]
    <h2 class="bibliography">Journal Articles</h2>
<h3 class="bibliography">2025</h3>
<ol class="bibliography"><li><!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="TRO_ATACOM"><div class="pub-illustration">
      <img src="/assets/img/air_hockey_atacom.gif" alt="Safe Reinforcement Learning on the Constraint Manifold: Theory and Applications illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Safe Reinforcement Learning on the Constraint Manifold: Theory and Applications
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">
            <em>Puze Liu</em>,&nbsp;Bou-Ammar Haitham,&nbsp;Jan Peters,&nbsp;and Tateo Davide
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    IEEE Transactions on Robotics (T-RO), vol. , pp. 3442-3461, 2025
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>]
      [<a href="http://arxiv.org/abs/2404.09080" class="btn btn-sm z-depth-0" role="button">arXiv</a>]
      [<a href="https://www.ias.informatik.tu-darmstadt.de/uploads/Team/PuzeLiu/TRO_ATACOM_submitted.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="https://puzeliu.github.io/TRO-ATACOM" class="btn btn-sm z-depth-0" role="button">URL</a>]
      [<a href="http://doi.org/10.1109/TRO.2025.3567477" class="btn btn-sm z-depth-0" role="button">DOI</a>]
    </div>

    <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Integrating learning-based techniques, especially reinforcement learning, into robotics is promising for solving complex problems in unstructured environments. However, most existing approaches are trained in well-tuned simulators and subsequently deployed on real robots without online fine-tuning. In this setting, the simulation’s realism seriously impacts the deployment’s success rate. Instead, learning with real-world interaction data offers a promising alternative: not only eliminates the need for a fine-tuned simulator but also applies to a broader range of tasks where accurate modeling is unfeasible. One major problem for on-robot reinforcement learning is ensuring safety, as uncontrolled exploration can cause catastrophic damage to the robot or the environment. Indeed, safety specifications, often represented as constraints, can be complex and non-linear, making safety challenging to guarantee in learning systems. In this paper, we show how we can impose complex safety constraints on learning-based robotics systems in a principled manner, both from theoretical and practical points of view. Our approach is based on the concept of the Constraint Manifold, representing the set of safe robot configurations. Exploiting differential geometry techniques, i.e., the tangent space, we can construct a safe action space, allowing learning agents to sample arbitrary actions while ensuring safety. We demonstrate the method’s effectiveness in a real-world Robot Air Hockey task, showing that our method can handle high-dimensional tasks with complex constraints. Videos of the real robot experiments are available on the project website.</p>
      </div>
  </div>
</div></li>
<li><!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="RAL_2025_Friction_Estimation"><div class="pub-illustration">
      <img src="/assets/img/adaptive_friction.jpg" alt="Adaptive control based friction estimation for tracking control of robot manipulators illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Adaptive control based friction estimation for tracking control of robot manipulators
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">Junning Huang,&nbsp;Davide Tateo,&nbsp;
            <em>Puze Liu</em>,&nbsp;and Jan Peters
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    IEEE Robotics and Automation Letters, vol. 10, pp. 2454-2461, 2025
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a href="https://arxiv.org/pdf/2409.05054" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="http://doi.org/10.1109/LRA.2025.3530159" class="btn btn-sm z-depth-0" role="button">DOI</a>]
    </div>

    
  </div>
</div></li></ol>
<h3 class="bibliography">2024</h3>
<ol class="bibliography"><li><!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="TRO_2024_Fast_Kinodynamic_Planning"><div class="pub-illustration">
      <img src="/assets/img/air_hockey_dynamic.gif" alt="Fast Kinodynamic Planning on the Constraint Manifold With Deep Neural Networks illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Fast Kinodynamic Planning on the Constraint Manifold With Deep Neural Networks
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">Piotr Kicki,&nbsp;
            <em>Puze Liu</em>,&nbsp;Davide Tateo,&nbsp;Haitham Bou-Ammar,&nbsp;Krzysztof Walas,&nbsp;Piotr Skrzypczyński,&nbsp;and Jan Peters
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    IEEE Transactions on Robotics (T-RO), vol. 40, pp. 277-297, 2024
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>]
      [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10292912" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="http://doi.org/10.1109/TRO.2023.3326922" class="btn btn-sm z-depth-0" role="button">DOI</a>]
    </div>

    <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Motion planning is a mature area of research in robotics with many well-established methods based on optimization or sampling the state space, suitable for solving kinematic motion planning. However, when dynamic motions under constraints are needed and computation time is limited, fast kinodynamic planning on the constraint manifold is indispensable. In recent years, learning-based solutions have become alternatives to classical approaches, but they still lack comprehensive handling of complex constraints, such as planning on a lower dimensional manifold of the task space while considering the robot’s dynamics. This article introduces a novel learning-to-plan framework that exploits the concept of constraint manifold, including dynamics, and neural planning methods. Our approach generates plans satisfying an arbitrary set of constraints and computes them in a short constant time, namely the inference time of a neural network. This allows the robot to plan and replan reactively, making our approach suitable for dynamic environments. We validate our approach on two simulated tasks and in a demanding real-world scenario, where we use a Kuka LBR Iiwa 14 robotic arm to perform the hitting movement in robotic air hockey.</p>
      </div>
  </div>
</div></li></ol>
<h2 class="bibliography">Conference Papers</h2>
<h3 class="bibliography">2025</h3>
<ol class="bibliography"><li><!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="CoRL_2025_SYMDEX"><div class="pub-illustration">
      <img src="/assets/img/symdex.gif" alt="Morphologically Symmetric Reinforcement Learning for Ambidextrous Bimanual Manipulation illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Morphologically Symmetric Reinforcement Learning for Ambidextrous Bimanual Manipulation
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">Zechu Li,&nbsp;Yufeng Jin,&nbsp;Daniel Ordonez Apraez,&nbsp;Claudio Semini,&nbsp;
            <em>Puze Liu*</em>,&nbsp;and Georgia Chalvatzaki
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In Conference on Robot Learning (CoRL), 2025
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a href="https://arxiv.org/pdf/2505.05287" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="https://supersglzc.github.io/projects/symdex" class="btn btn-sm z-depth-0" role="button">URL</a>]
    </div>

    
  </div>
</div></li></ol>
<h3 class="bibliography">2024</h3>
<ol class="bibliography"><li><!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="CoRL_2024_DATACOM"><div class="pub-illustration">
      <img src="/assets/img/datacom.gif" alt="Handling Long-Term Safety and Uncertainty in Safe Reinforcement Learning illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Handling Long-Term Safety and Uncertainty in Safe Reinforcement Learning
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">Jonas Günster,&nbsp;
            <em>Puze Liu*</em>,&nbsp;Jan Peters,&nbsp;and Davide Tateo
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In 8th Annual Conference on Robot Learning, 2024
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a href="https://openreview.net/pdf?id=97QXO0uBEO" class="btn btn-sm z-depth-0" role="button">PDF</a>]
    </div>

    
  </div>
</div></li>
<li><!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="NeurIPS_2024_Challenge"><div class="pub-illustration">
      <img src="/assets/img/air_hockey_challenge.jpg" alt="A Retrospective on the Robot Air Hockey Challenge: Benchmarking Robust, Reliable, and Safe Learning Techniques for Real-World Robotics illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">A Retrospective on the Robot Air Hockey Challenge: Benchmarking Robust, Reliable, and Safe Learning Techniques for Real-World Robotics
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">
            <em>Puze Liu</em>,&nbsp;Jonas Günster,&nbsp;Niklas Funk,&nbsp;Simon Gröger,&nbsp;Dong Chen,&nbsp;Haitham Bou-Ammar,&nbsp;Julius Jankowski,&nbsp;Ante Marić,&nbsp;Sylvain Calinon,&nbsp;Andrej Orsula,&nbsp;Miguel Olivares-Mendez,&nbsp;Hongyi Zhou,&nbsp;Rudolf Lioutikov,&nbsp;Gerhard Neumann,&nbsp;Amarildo Likmeta,&nbsp;Amirhossein Zhalehmehrabi,&nbsp;Thomas Bonenfant,&nbsp;Marcello Restelli,&nbsp;Davide Tateo,&nbsp;Ziyuan Liu,&nbsp;and Jan Peters
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In Proceedings of the 38th International Conference on Neural Information Processing Systems, 2024
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>]
      [<a href="https://openreview.net/pdf?id=gPLE4siNjO" class="btn btn-sm z-depth-0" role="button">PDF</a>]
    </div>

    <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Machine learning methods have a groundbreaking impact in many application domains, but their application on real robotic platforms is still limited. Despite the many challenges associated with combining machine learning technology with robotics, robot learning remains one of the most promising directions for enhancing the capabilities of robots. When deploying learning-based approaches on real robots, extra effort is required to address the challenges posed by various real-world factors. To investigate the key factors influencing real-world deployment and to encourage original solutions from different researchers, we organized the Robot Air Hockey Challenge at the NeurIPS 2023 conference. We selected the air hockey task as a benchmark, encompassing low-level robotics problems and high-level tactics. Different from other machine learning-centric benchmarks, participants need to tackle practical challenges in robotics, such as the sim-to-real gap, low-level control issues, safety problems, real-time requirements, and the limited availability of real-world data. Furthermore, we focus on a dynamic environment, removing the typical assumption of quasi-static motions of other real-world benchmarks. The competition’s results show that solutions combining learning-based approaches with prior knowledge outperform those relying solely on data when real-world deployment is challenging. Our ablation study reveals which real-world factors may be overlooked when building a learning-based solution. The successful real-world air hockey deployment of best-performing agents sets the foundation for future competitions and follow-up research directions.</p>
      </div>
  </div>
</div></li></ol>
<h3 class="bibliography">2023</h3>
<ol class="bibliography"><li><!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="ICRA_2022_ReDSDF_ATACOM"><div class="pub-illustration">
      <img src="/assets/img/hri_real.gif" alt="Safe Reinforcement Learning of Dynamic High-Dimensional Robotic Tasks: Navigation, Manipulation, Interaction illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Safe Reinforcement Learning of Dynamic High-Dimensional Robotic Tasks: Navigation, Manipulation, Interaction
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">
            <em>Puze Liu</em>,&nbsp;Kuo Zhang,&nbsp;Davide Tateo,&nbsp;Snehal Jauhri,&nbsp;Zhiyuan Hu,&nbsp;Jan Peters,&nbsp;and Georgia Chalvatzaki
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), 2023
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>]
      [<a href="http://arxiv.org/abs/2209.13308" class="btn btn-sm z-depth-0" role="button">arXiv</a>]
      [<a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>]
      [<a href="https://arxiv.org/pdf/2209.13308.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>]
    </div>

    <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Safety is a crucial property of every robotic platform: any control policy should always comply with actuator limits and avoid 
                 collisions with the environment and humans. In reinforcement learning, safety is even more fundamental for exploring an 
                 environment without causing any damage. While there are many proposed solutions to the safe exploration problem, only a few of 
                 them can deal with the complexity of the real world. This paper introduces a new formulation of safe exploration for reinforcement 
                 learning of various robotic tasks. Our approach applies to a wide class of robotic platforms and enforces safety even under 
                 complex collision constraints learned from data by exploring the tangent space of the constraint manifold. Our proposed approach 
                 achieves state-of-the-art performance in simulated high-dimensional and dynamic tasks while avoiding collisions with the 
                 environment. We show safe real-world deployment of our learned controller on a TIAGo++ robot, achieving remarkable performance 
                 in manipulation and human-robot interaction tasks.</p>
      </div><!-- Hidden bibtex block -->
      <div class="bibtex hidden">
        <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ICRA_2022_ReDSDF_ATACOM</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Safe Reinforcement Learning of Dynamic High-Dimensional Robotic Tasks: Navigation, Manipulation, Interaction}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Puze and Zhang, Kuo and Tateo, Davide and Jauhri, Snehal and Hu, Zhiyuan and Peters, Jan and Chalvatzaki, Georgia}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">image</span> <span class="p">=</span> <span class="s">{/assets/img/hri_real.gif}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
      </div>
  </div>
</div></li></ol>
<h3 class="bibliography">2022</h3>
<ol class="bibliography"><li><!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="IROS_2022_ReDSDF"><div class="pub-illustration">
      <img src="/assets/img/tiago_sdf.gif" alt="Regularized Deep Signed Distance Fields for Reactive Motion Generation illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Regularized Deep Signed Distance Fields for Reactive Motion Generation
    <!-- Additional Comments --></div>  
  <!-- Author -->
  <div class="author">
            <em>Puze Liu</em>,&nbsp;Kuo Zhang,&nbsp;Davide Tateo,&nbsp;Snehal Jauhri,&nbsp;Jan Peters,&nbsp;and Chalvatzaki Georgia
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2022
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>]
      [<a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>]
      [<a href="https://www.ias.informatik.tu-darmstadt.de/uploads/Team/PuzeLiu/IROS_2022_ReDSDF.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="https://git.ias.informatik.tu-darmstadt.de/ias_code/iros2022/redsdf" class="btn btn-sm z-depth-0" role="button">Code</a>]
    </div>

    <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Autonomous robots should operate in real-world dynamic environments and collaborate with humans in tight spaces. A key component for allowing robots to leave structured lab and manufacturing settings is their ability to evaluate online and real-time collisions with the world around them. Distance-based constraints are fundamental for enabling robots to plan their actions and act safely, protecting both humans and their hardware. However, different applications require different distance resolutions, leading to various heuristic approaches for measuring distance fields w.r.t. obstacles, which are computationally expensive and hinder their application in dynamic obstacle avoidance use-cases. We propose Regularized Deep Signed Distance Fields (ReDSDF), a single neural implicit function that can compute smooth distance fields at any scale, with fine-grained resolution over high-dimensional manifolds and articulated bodies like humans, thanks to our effective data generation and a simple inductive bias during training. We demonstrate the effectiveness of our approach in representative simulated tasks for whole-body control (WBC) and safe Human-Robot Interaction (HRI) in shared workspaces. Finally, we provide proof of concept of a real-world application in a HRI handover task with a mobile manipulator robot.</p>
      </div><!-- Hidden bibtex block -->
      <div class="bibtex hidden">
        <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">IROS_2022_ReDSDF</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Regularized Deep Signed Distance Fields for Reactive Motion Generation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Puze and Zhang, Kuo and Tateo, Davide and Jauhri, Snehal and Peters, Jan and Georgia, Chalvatzaki}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">image</span> <span class="p">=</span> <span class="s">{/assets/img/tiago_sdf.gif}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
      </div>
  </div>
</div></li>
<li><!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="CORL_2021_ATACOM"><div class="pub-illustration">
      <img src="/assets/img/manifold.gif" alt="Robot Reinforcement Learning on the Constraint Manifold illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Robot Reinforcement Learning on the Constraint Manifold
    <!-- Additional Comments --><div class="comments">
    Best Paper Award Finalist
  </div></div>  
  <!-- Author -->
  <div class="author">
            <em>Puze Liu</em>,&nbsp;Davide Tateo,&nbsp;Haitham Bou-Ammar,&nbsp;and Jan Peters
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In Proceedings of the 5th Conference on Robot Learning (CoRL), vol. 164, pp. 1357–1366, 2022
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>]
      [<a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>]
      [<a href="https://proceedings.mlr.press/v164/liu22c/liu22c.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="https://proceedings.mlr.press/v164/liu22c.html" class="btn btn-sm z-depth-0" role="button">Supp</a>]
      [<a href="https://github.com/PuzeLiu/rl_on_manifold" class="btn btn-sm z-depth-0" role="button">Code</a>]
      [<a href="https://www.youtube.com/watch?v=1Ve4wig7Oi4" class="btn btn-sm z-depth-0" role="button">Website</a>]
    </div>

    <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Reinforcement learning in robotics is extremely challenging due to many practical issues, including safety, mechanical constraints, and wear and tear. Typically, these issues are not considered in the machine learning literature. One crucial problem in applying reinforcement learning in the real world is Safe Exploration, which requires physical and safety constraints satisfaction throughout the learning process.  To explore in such a safety-critical environment, leveraging known information such as robot models and constraints is beneficial to provide more robust safety guarantees. Exploiting this knowledge, we propose a novel method to learn robotics tasks in simulation efficiently while satisfying the constraints during the learning process.</p>
      </div><!-- Hidden bibtex block -->
      <div class="bibtex hidden">
        <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CORL_2021_ATACOM</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Robot Reinforcement Learning on the Constraint Manifold}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Puze and Tateo, Davide and Bou-Ammar, Haitham and Peters, Jan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 5th Conference on Robot Learning (CoRL)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1357--1366}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Faust, Aleksandra and Hsu, David and Neumann, Gerhard}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{164}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
  <span class="na">comments</span> <span class="p">=</span> <span class="s">{Best Paper Award Finalist}</span><span class="p">,</span>
  <span class="na">image</span> <span class="p">=</span> <span class="s">{/assets/img/manifold.gif}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
      </div>
  </div>
</div></li></ol>
<h3 class="bibliography">2021</h3>
<ol class="bibliography"><li><!-- Entry with optional illustration (image or video) --><div class="pub-entry" id="IROS_2021_Air_Hockey"><div class="pub-illustration">
      <img src="/assets/img/air_hockey_iros.jpg" alt="Efficient and Reactive Planning for High Speed Robot Air Hockey illustration">
    </div><div class="pub-content">
    
  <!-- Title -->
  <div class="title">Efficient and Reactive Planning for High Speed Robot Air Hockey
    <!-- Additional Comments --><div class="comments">
    Best Entertainment and Amusement Paper Award Finalist
  </div></div>  
  <!-- Author -->
  <div class="author">
            <em>Puze Liu</em>,&nbsp;Davide Tateo,&nbsp;Haitham Bou-Ammar,&nbsp;and Jan Peters
  </div>

  <!-- Journal/Book title and date -->
  
  <div class="third-line">
    In 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 586-593, 2021
  </div>

    <!-- Links/Buttons -->
    <div class="links">
      [<a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>]
      [<a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>]
      [<a href="https://ieeexplore.ieee.org/document/9636263" class="btn btn-sm z-depth-0" role="button">HTML</a>]
      [<a href="https://www.ias.informatik.tu-darmstadt.de/uploads/Team/PuzeLiu/IROS_2021_Air_Hockey.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>]
      [<a href="http://doi.org/10.1109/IROS51168.2021.9636263" class="btn btn-sm z-depth-0" role="button">DOI</a>]
    </div>

    <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Highly dynamic robotic tasks require high-speed and reactive robots. These tasks are particularly challenging due to the physical constraints, hardware limitations, and the high uncertainty of dynamics and sensor measures. To face these issues, it’s crucial to design robotics agents that generate precise and fast trajectories and react immediately to environmental changes. Air hockey is an example of this kind of task. Due to the environment’s characteristics, it is possible to formalize the problem and derive clean mathematical solutions. For these reasons, this environment is perfect for pushing to the limit the performance of currently available general-purpose robotic manipulators. Using two Kuka Iiwa 14, we show how to design a policy for general-purpose robotic manipulators for the air hockey game. We demonstrate that a real robot arm can perform fast-hitting movements and that the two robots can play against each other on a medium-size air hockey table in simulation.</p>
      </div><!-- Hidden bibtex block -->
      <div class="bibtex hidden">
        <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">IROS_2021_Air_Hockey</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Efficient and Reactive Planning for High Speed Robot Air Hockey}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Puze and Tateo, Davide and Bou-Ammar, Haitham and Peters, Jan}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{586-593}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IROS51168.2021.9636263}</span><span class="p">,</span>
  <span class="na">comments</span> <span class="p">=</span> <span class="s">{Best Entertainment and Amusement Paper Award Finalist}</span><span class="p">,</span>
  <span class="na">image</span> <span class="p">=</span> <span class="s">{/assets/img/air_hockey_iros.jpg}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
      </div>
  </div>
</div></li></ol>
  </div>
</section>

  
</div>

<!-- Footer -->
<footer>
  <div class="footer">
    Copyright © 2025
    <a href="">Puze Liu</a>.
    Powered by Jekyll.
  </div>
</footer>


<script type="text/javascript" src="/assets/js/jquery-3.3.1.min.js"></script>
<script type="text/javascript" src="/assets/js/Headroom.js"></script>
<script type="text/javascript" src="/assets/js/jQuery.headroom.js"></script>
<script type="text/javascript" src="/assets/js/custom.js"></script>


<script>
    var divs = document.querySelectorAll("div.project-content");
    $('div.project-content').each(function (index) { 
        var filename = $(this).text();
        filename = filename.replace(/\s/g, '');
        filename = filename.replace("/_posts/", "");
        filename = filename.replace(".md", ".html");
        filename = filename.substring(0, 4) + "/" + filename.substring(5);
        filename = filename.substring(0, 7) + "/" + filename.substring(8);
        filename = filename.substring(0, 10) + "/" + filename.substring(11);

        console.log(filename);
        $.ajax({ url: filename, dataType: "html", success: function(data) { 
            const node = new DOMParser().parseFromString(data, "text/html");
            divs[index].innerHTML = node.getElementById("post").getElementsByClassName("post-content")[0].innerHTML;
            } 
        })
    });

</script>
  </div>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css" integrity="sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js" integrity="sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          // customised options
          // • auto-render specific keys, e.g.:
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          // • rendering keys, e.g.:
          throwOnError : false
        });
    });
</script>
  <script type="module">
    // Import the functions you need from the SDKs you need
    import { initializeApp } from "https://www.gstatic.com/firebasejs/9.10.0/firebase-app.js";
    import { getAnalytics } from "https://www.gstatic.com/firebasejs/9.10.0/firebase-analytics.js";
    // TODO: Add SDKs for Firebase products that you want to use
    // https://firebase.google.com/docs/web/setup#available-libraries

    // Your web app's Firebase configuration
    // For Firebase JS SDK v7.20.0 and later, measurementId is optional
    const firebaseConfig = {
        apiKey: "AIzaSyB7md8A_0alXIvUwSlpHGW8F-i59SboSqE",
        authDomain: "puze-liu.firebaseapp.com",
        projectId: "puze-liu",
        storageBucket: "puze-liu.appspot.com",
        messagingSenderId: "895154462267",
        appId: "1:895154462267:web:b6265ec90951a8bc62061e",
        measurementId: "G-97L9JYTYVW"
    };

    // Initialize Firebase
    const app = initializeApp(firebaseConfig);
    const analytics = getAnalytics(app);
</script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-RNQHE0TJJL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-RNQHE0TJJL');
</script>
</body>

</html>